{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries we need\n",
    "import os\n",
    "\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "from parsl.channels import LocalChannel\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.providers import LocalProvider\n",
    "\n",
    "# Helper functions\n",
    "from grouputils import initialize_stager\n",
    "from grouputils import plot_tiles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The first step in our workflow is to \"stage\" our data. Staging the data encompasses the following pre-processing tasks:\n",
    "\n",
    "- simplify the polygons \n",
    "- set an input CRS if one is missing\n",
    "- reproject the data when required\n",
    "- add additional properties to each polygon, including:\n",
    "  - the centroid x and y coordinates\n",
    "  - area\n",
    "  - a unique ID\n",
    "  - name of the file that the\n",
    "  polygon originated from\n",
    "- break each input file into [standardized tiles](https://docs.opengeospatial.org/is/17-083r2/17-083r2.html)\n",
    "- identify duplicate polygons (those that occur in two staged tiles)\n",
    "- save them to disk, following a file hierarchy and naming format for x, y, and z coordinates of the tiles\n",
    "\n",
    "Here is a diagram showing what the most important step, the last one, looks like.\n",
    "\n",
    "![](https://raw.githubusercontent.com/PermafrostDiscoveryGateway/viz-staging/develop/docs/images/staging_tldr.png)\n",
    "\n",
    "We will use some methods from the `pdgstaging` library to stage our tiles. The first step, is to initalize the `TileStager`. The `TileStager` is a class with a method `stage`, which works on a single vector file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize the stager\n",
    "\n",
    "Fist we need to use the `initialize_stager` function to instantiate the `TileStager` object. The only argument to this function is `dir_input`, the directory of input data.\n",
    "\n",
    "Input vector files are located **in `/home/shares/example-pdg-data`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the initialize_stager function with the filepath for the input data\n",
    "# Save the result to a variable called iwp_stager\n",
    "iwp_stager = initialize_stager(\"/home/shares/example-pdg-data/SCC-2023\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iwp_stager` object works as a tool that communicates between the configuration settings and the staging function. The stager tells the staging function:\n",
    "- where to pull the input files from\n",
    "- where to write the staged tiles\n",
    "- the coordinate reference system to use\n",
    "- whether the input data should be deduplicated, etc.\n",
    "\n",
    "Next let's use it to get a list of files to stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_stage = iwp_stager.tiles.get_filenames_from_dir('input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage one file\n",
    "\n",
    "Here is an example of how to run the stager on one file. We use the `stage` method on the `iwp_stager` object, with a path to a file as the argument to the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file = files_to_stage[1] # file = 88.3 MB\n",
    "\n",
    "iwp_stager.stage(example_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your driectory `scalable-computing-course/group-project` - you'll see that a subdirectory called `staged` has been created. This directory contains the `.gpkg` files output. To check how many staged files were created, you can run the command: `find group-project/staged -type f | wc -l`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating total computation time\n",
    "\n",
    "Based on how long staging one file took, estimate how long that would take to stage all 11 input files, serially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate computation time for 11 files\n",
    "(11)*(55) # answer in seconds\n",
    "num_minutes = (11*55)/60 # answer in minutes\n",
    "\n",
    "print(f\"Staging 11 input GeoPackages would take {round(num_minutes)} minutes without parallelization.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the different sizes of each input file, it can be difficult to predict how long it will actually take. All the files that make up this small data sample are very small relative to other files in the compelete dataset, so our calculation results in an underestimate when we scale up the workflow. The largest file in this dataset is 88.2 GB, and an average ice wedge polygon file is around 400 MB, resulting in a processing time of many minutes.\n",
    "\n",
    "Additionally, a computer's resources are limited by the amount of people concurrently processing files and writing them (I/0 wait). When a machine is writing a file, it is not \"working\", it's waiting for the file to be written. When many users are writing files, a queue builds up."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling up the workflow\n",
    "\n",
    "Computation time also depends on the machine you're working on. With more input GeoPackages from this dataset, it is common to run into an \"out of memory\" error that cancels the entire process when run serially. Tools such as `htop` and `glances` help with monitorting memory, CPU usage, and which accounts are runnning each process on a server. If a process is running slower than you would expect, you can check these dashboards to diagnose the problem. If your dashbord shows your memory is steadily increasing and reaches >90%, that's a sign your process will crash! When doing test runs with your data, it is important to monitor your memory to determine how the usage will increase in addition to the number of output files. \n",
    "\n",
    "The complete ice wedge polygon dataset contains **26,530** GeoPackages. How long would it take to process all of them serially, assuming they all took the same amount of time as our example file? Recall this your answer will be an underestimate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate computation time for all 26,530 files\n",
    "(26530)*(55) # answer in seconds\n",
    "(26530*55)/60 # answer in minutes\n",
    "(26530*55)/60/60 # answer in hours\n",
    "num_days = (26530*55)/60/60/24 # answer in days\n",
    "\n",
    "print(f\"Staging all 26,530 input GeoPackages would take {round(num_days)} days without parallelization.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing staged tiles\n",
    "\n",
    "As the number of files gets bigger, things get out of hand quickly. Luckily for us, this problem is pleasingly parallel. The staging of each file is completely independent of the others. So, let's set this up as a `parsl` workflow using the skills we learned in Section 4: Pleasingly Parallel Programming.\n",
    "\n",
    "Just to get a sense of what happened, let's plot the result of our test staging effort using a `plot_tiles` helper function we wrote for this activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tiles(iwp_stager) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's remove the files we just created (including the staging summary csv file that's generated with the staged files) to prepare to run this over all of the files. If we don't do this, polygons will get appended to the staged files which will result in duplication.\n",
    "\n",
    "We also need to refresh the stager to its original state for a new staging instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove files and staged directory\n",
    "os.system(f'rm -rf {iwp_stager.config.get(\"dir_staged\")}')\n",
    "os.system(f'rm {iwp_stager.config.get(\"filename_staging_summary\")}')\n",
    "\n",
    "# Refresh the stager\n",
    "iwp_stager = initialize_stager(\"/home/shares/example-pdg-data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staging in parallel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up the configuration for `parsl` using `config`, and a `HighThroughputExecutor` (`parsl` has many exector options). We are working on a single node with 88 cores, so we have the choice between `HighThroughputExecutor` or `ThreadPoolExecutor`. We chose to use `HighThroughputExecutor` because it avoids a long job scheduler queue delays by aquiring a set of resources initially, allowing it to schedule _multiple tasks_ on a single node! Using the other exector actually makes our execution time _much_ longer.\n",
    "\n",
    "\n",
    "For the executor, set the `max_workers` to 11, and set the `max_blocks` to 1. This will spread our work over 11 processes on the server.\n",
    "\n",
    "A \"block\" is the most basic unit of resources to be aquired from a provider. A block has a different definition depending on the kind of server you're working on (whether you have been allocated multiple nodes, or do work on _one node_ that has multiple _cores_). We are working on a multi-core node, we wouldn't want to set our blocks to be higher than 1, because a block _at minimum_ is 1 node. There are plenty of `parsl` configuration options out there, but many are not relevant for our server and do not speed up the process. \n",
    "\n",
    "\n",
    "\n",
    "Make sure you pass the bash command you use to invoke your virtual environment to the `worker_init` argument as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPLATE FOR PARSL CONFIG:\n",
    "\n",
    "# activate_env = 'workon scomp'\n",
    "# htex_config = Config(\n",
    "#   executors=[\n",
    "#       HighThroughputExecutor(\n",
    "#           ..., \n",
    "#           provider = LocalProvider(\n",
    "#             worker_init = activate_env,\n",
    "#             ...\n",
    "#           )\n",
    "#       )\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "activate_env = 'workon scomp'\n",
    "htex_local = Config(\n",
    "    executors = [\n",
    "        HighThroughputExecutor(\n",
    "            max_workers = 11, # Caps the number of workers launched per node (5 groups with 11 workers each)\n",
    "            provider = LocalProvider(\n",
    "                worker_init = activate_env,\n",
    "                max_blocks = 1\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "parsl.clear()\n",
    "parsl.load(htex_local)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up your Parsl app to run the `stage` method in parallel. You'll need to pass 2 arguments to the app function:\n",
    "1. The path to the input file.\n",
    "2. The `TileStager` instance we created earlier.\n",
    "\n",
    "Note how the function returns the input path. This will give us something to interate over, since the `stage` method returns `None` (and writes files!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Parsl app that uses the stage method\n",
    "# Function arguments: path, stager\n",
    "@python_app\n",
    "def stage_file(path, stager):\n",
    "    stager.stage(path) \n",
    "    return path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the app in parallel over all of the `files_to_stage`. In this solution, we use a simple loop to run our `parsl` app, and then list comprehension to retrieve the result from our futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the app using app.futures\n",
    "all_app_futures = []\n",
    "for path in files_to_stage:\n",
    "    app_future = stage_file(path, iwp_stager)\n",
    "    all_app_futures.append(app_future)\n",
    "\n",
    "# By getting the `result()` of each app future, this block won't continue to \n",
    "# the print statement until all the files are staged.\n",
    "[app_future.result() for app_future in all_app_futures] \n",
    "\n",
    "print(\"All input files have been staged.\")\n",
    "\n",
    "# took 25-35 min to produce 2249 gpkg files from 35 input files\n",
    "# took 30 minutes to produce 1630 gpkg files from 20 input files (first 20)\n",
    "# took 20 minutes to produce 1100 gpkg files from 15 input files (last 15)\n",
    "# took 17 minutes to produce 1082 gpkg files from 15 input files (first 15) with 25 workers, took 36 without parallelization! saved us ~20 min\n",
    "# took 15 minutes to produce 1082 gpkg files from 15 input files (first 15), with 15 workers\n",
    "# took 45 minutes to produce 1082 gpkg files from 15 input files (first 15), with 15 workers, with 4 people running parsl code at once\n",
    "# took 4-5 minutes to produce 454 gpkg files from 11 smallest input files, with 11 workers, with just me running parsl code\n",
    "# took 6 minutes to produce 454 gpkg files from 11 smallest input files, with 11 workers, with parallellism = 1\n",
    "# took 3.5 minutes to produce 454 gpkg files from 11 smallest input files, with 11 workers, with parallellism = 0.5, min_blocks = 1, max_blocks = 2\n",
    "# took 5 minutes to produce 454 gpkg files from 11 smallest input files, with 15 workers, with parallellism = 0.5, min_blocks = 1, max_blocks = 2\n",
    "# threadpoolexecutor took way too long!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to shutdown your executor and clear `parsl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown and clear the parsl executor\n",
    "htex_local.executors[0].shutdown()\n",
    "parsl.clear()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check out the `plot_tiles` result again (which will only plot the first 45 of our tiled files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tiles(iwp_stager)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Questions\n",
    "\n",
    "This process took the original 11 files, ranging in size from 6 MB to 88 MB (all files = about 0.5 GB), and tiled them into 454 geopackage files. \n",
    "\n",
    "Discuss in your groups whether you suspect this process is CPU bound, I/O bound, memory bound, or network bound. \n",
    "\n",
    "How would you figure it out for sure?\n",
    "\n",
    "Why would you want to know?\n",
    "\n",
    "### Answers\n",
    "\n",
    "This process seems to be I/O bound.\n",
    "\n",
    "We can rule out memory bound, since the total data to process is ~2GB and the memory on our server is much greater than that (126 GB). It is also not network bound, since all of the data are local to our process, and don't need to be transferred at all.\n",
    "\n",
    "This leaves CPU or I/O bound. One way to test whether the process is CPU bound is to see if adding more workers (CPU power) decreases the computation time. Spoiler: it doesn't! If you increase the number of workers in the executor, the process still takes around 15-17 minutes to finish. Additionally, the CPU load and CPU utilization remain approximately the same. To check out the CPU load during a process (amongst other stats) the command line `dstat` is helpful. I like `dstat -a --load` to look at CPU load specifically.\n",
    "\n",
    "So now we are leaning towards I/O bound, which makes sense, given that we are reading in some decently sized files, and then having to write out a whole bunch of files. How can we confirm? The commandline tool `iostat` (`iostat -kx 1`) will show the percentage of CPU time during which I/O requests are sent in the `%util` column. A high percentage here is a potential indicator that your process is I/O limited. Other stats to look at are the disk latency and request wait time, both of which are indicators that the process is waiting a while for things to finish writing to disk. The way to test all this, of course, would be to run the process on a machine with a faster disk to see if you can decrease your process time.\n",
    "\n",
    "As for why we would want to know this, if we wanted to speed up our process, and it is I/O bound, throwing more CPU at it will not make it faster (as just discussed). So it is important to know the nature of the problem, so that you can address it appropriately.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Exercise: using scripts\n",
    "\n",
    "Once you have established your workflow in using a notebook, executing your code in a `.py` script will save you time in the future, especially if you intend to run your workflow again and again on new input data, which is the case for the ice wedge polygon dataset! Additionally, scripts are a more common way to share code with collaborators since they have simple formatting on the backend, and are easier to handle with GitHub. \n",
    "\n",
    "Instead of executing the same code we just ran in this notebook, let's use a script to explore the data we just produced. Using the command we learned earlier (`find group-project/staged -type f | wc -l`) we can check the number of output files. There should be 454. Each of those is a GeoPackage that contains many polygons and their attributes. 1 polygon = 1 row. \n",
    "\n",
    "1. Create a blank script in your `scalable-computing-course` with the `touch` command: `touch count_polygons.py`\n",
    "2. At the top of the script, import the packages you'll need:\n",
    "```python\n",
    "import geopandas as gpd\n",
    "from grouputils import initialize_stager\n",
    "```\n",
    "3. Initialize your stager.\n",
    "4. Pull in all the filepaths from the `staged` directory.\n",
    "5. Create a loop that opens each of the staged files, determines the number of rows, and appends that value to a list.\n",
    "4. Sum the values in the list, and insert a print statement for it. That's the number of total polygons we see in our plot!\n",
    "5. Run your script with the command `python count_polygons.py`. Make sure your environment is activated in the terminal first.\n",
    "\n",
    "Once you have completed that, you can also adjust the script to explore polygon attributes.\n",
    "\n",
    "A great command line tool for running long scripts on servers is `tmux`, which will continue running the script even if your connection to the server is disconnected! It also frees you up to do other work on the server while that chugs away in the background.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('scomp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0030ed2ed4c0609037967981d5426019e14a913516344490dbc8ffbbe92f86b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
