{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up imports\n",
    "import xarray as xr\n",
    "from pystac_client import Client\n",
    "import stackstac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring STAC catalogs using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAC is a specification for describing spatiotemporal data assets, intended to facilite search and discovery of relevant data, especially based on spatial and/or temporal queries of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CEDA STAC API\n",
    "\n",
    "STAC API provided by the Centre for Environmental Data Analysis (UK)\n",
    "\n",
    "STAC Browser: https://stac.ceda.ac.uk/?.language=en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we open a connection to the root-level catalog..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'https://api.stac.ceda.ac.uk/'\n",
    "catalog = Client.open(uri)\n",
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now grab all the collections in the catalog, and print out a list of the IDs and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = catalog.get_all_collections()\n",
    "for collection in collections:\n",
    "    print(f'[{collection.id}]: {collection.title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look closer at the monthly Arctic sea ice thickness collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_collection_id = 'eocis-arctic-sea-ice-thickness-monthly'\n",
    "ice_collection = catalog.get_collection(ice_collection_id)\n",
    "ice_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular catalog supports `search` requests, so let's do a first search that looks for all items in the ice collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_item_collection = catalog.search(\n",
    "        collections=[ice_collection.id]\n",
    "    ).item_collection()\n",
    "\n",
    "print(f'Returned {len(ice_item_collection)} items')\n",
    "print('First 5 items:')\n",
    "ice_item_collection.items[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the bread-and-butter of STAC. We'll repeat the search, now applying a combination of spatial and temporal constraints to further limit the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_item_subset = catalog.search(\n",
    "    collections=[ice_collection.id],\n",
    "    bbox=[-157.223175, 71.134346, -155.816925, 71.388457],\n",
    "    datetime='2020'\n",
    ").item_collection()\n",
    "\n",
    "print(f'Retrieved {len(ice_item_subset)} items for collection {ice_collection.id}')\n",
    "ice_item_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can retrieve an item by ID from the collection, where the collection has been retrieve by ID from the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_item = catalog \\\n",
    "    .get_collection(ice_collection.id) \\\n",
    "    .get_item('ea60feff-3a21-49d1-b79f-9179c052cfc0')\n",
    "ice_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click into the `assets` in the entry above. It's a kerchunk \"dataset\"! In a nutshell, this is a Zarr store in which the data references point \"into\" linked netCDF files, with byte ranges corresponding to the segments of the file holding the relevant \"chunks\" of interest. Everything connects :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('http')\n",
    "\n",
    "kerchunk_href = ice_item.assets['reference_file'].href\n",
    "with fs.open(kerchunk_href) as f:\n",
    "    print(json.dumps(json.load(f), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover Sentinel COGs and create a stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hat tip: This tutorial is based on https://www.geodose.com/2024/02/pystac-decoded-step-by-step-tutorial.html\n",
    "\n",
    "See online browser: https://stacindex.org/catalogs/earth-search#/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's connect to the top-level catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'https://earth-search.aws.element84.com/v1'\n",
    "catalog = Client.open(uri)\n",
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll see what collections are stored at that Catalog level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_list = list(catalog.get_collections())\n",
    "print(f\"Catalog contains {len(collection_list)} collections\")\n",
    "for collection in collection_list:\n",
    "    print(f'- [{collection.id}] {collection.title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dive into the `sentinel-2-l2a` collection.\n",
    "\n",
    "In the returned widget, look at some of the details. Especially take note of:\n",
    "- **extent**: Note the information about the _spatial_ and _temporal_ coverage of this collection. This is central to STAC!\n",
    "- **item_asset**\n",
    "- ... and more ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_collection_id = 'sentinel-2-l2a'\n",
    "catalog.get_collection(sentinel_collection_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this collection contain? For starts ... how big is the collection, in terms of the number of items?\n",
    "\n",
    "Here's a trick to get a total item count: We do an search on the catalog, specifically referencing the collection of interest, but otherwise not providing any query constraints. Importantly, we'll tell this method not to return any items. Then we'll invoke the `matched()` method on this returned object, reporting the total count of \"matched\" items -- which in this case is the total count of items in the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = catalog.search(collections=[sentinel_collection_id], max_items=0).matched()\n",
    "print(f'Found {n:,} items in the {sentinel_collection_id} collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a smaller collection, we could bring back all of the item information \n",
    "# in a list. But for 40M, we don't want to do this :)\n",
    "# [item.id for item in catalog.get_collection('sentinel-2-l2a').get_items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get down to the **item** level. Quoting the STAC spec (with emphasis added):\n",
    ">An Item is a GeoJSON Feature augmented with foreign members relevant to a STAC object. These include fields that identify the time range and assets of the Item. **An Item is the core object in a STAC Catalog**, containing the core metadata that enables any client to search or crawl online catalogs of spatial 'assets' (e.g., satellite imagery, derived data, DEMs).\n",
    "\n",
    "\n",
    "To retrieve some items, we'll go back to the `catalog.search()` method, but this time providing some significant restrictions on what we want. In particular, we'll limit by **geographic extent** using a (hand-created) bounding box corresponding to a small area near Utqiagvik, and by temporal extent using a date range spanning a few months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://linestrings.com/bbox/#-156.8,71.25,-156.7,71.3\n",
    "east, west, north, south = -156.7, -156.8, 71.3, 71.25\n",
    "bbox_utqiagvik = [west, south, east, north]\n",
    "\n",
    "item_collection = catalog.search(\n",
    "    #intersects=dict(type=\"Point\", coordinates=[lon, lat]),\n",
    "    collections=[sentinel_collection_id],\n",
    "    bbox = bbox_utqiagvik,\n",
    "    datetime=\"2020-03-01/2020-06-01\"\n",
    ").item_collection()\n",
    "\n",
    "print(f'Returned {len(item_collection)} items')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in item_collection.items[:10]:\n",
    "    print(item.id,\":\", item.properties['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first item. Now the specific geographic extent of the associated item assets are recorded in the **geometry** and **bbox** entries, and the temporal information is stored in **properties -> datetime**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_collection.items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, STAC items are still _catalog entries_, not the underlying data or other artifact! STAC doesn't actually store data, but like any useful catalog, it tells you were to find. In STAC parlance, the \"things\" it refers to are called **assets**, which \"belong\" to an item. An item can refer to many assets. You can see them under the **assets** intry in the catalog visualizer above, or access them in a dictionary-like way using the `assets` accessor on the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_collection.items[0].assets['nir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information above, we can see that the _nir_ reflectance data artifact corresponding to this asset is stored as a cloud-optimized GeoTIFF in AWS S3 storage. We can take the individual COG URL and throw it in [this cool interactive COG web mapper site](https://cholmes.github.io/cog-map/#/url/https%3A%2F%2Fsentinel-cogs.s3.us-west-2.amazonaws.com%2Fsentinel-s2-l2a-cogs%2F4%2FW%2FEE%2F2020%2F6%2FS2B_4WEE_20200601_1_L2A%2FB08.tif/center/-155.658,70.152/zoom/6.2), and could of course load this into Python using `rasterio` or `rioxarray`, depending on our preference.\n",
    "\n",
    "Here's an example using xarrarry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "\n",
    "href = \"https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/4/W/EE/2020/6/S2B_4WEE_20200601_1_L2A/B08.tif\"\n",
    "rx_nir = rioxarray.open_rasterio(href, chunks={})\n",
    "# could also use xr.open_dataarray(href, engine='rasterio', chunks='auto')\n",
    "\n",
    "rx_nir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_nir.squeeze()[-1500:, -1500:].plot.imshow();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to assemble a bunch of COGs for different dates? We could do it manually. Or ... `stackstac` to the rescue!\n",
    "\n",
    "From [their documentation](https://stackstac.readthedocs.io/en/latest/api/main/stackstac.stack.html), here's what `stackstac` does for you:\n",
    "> - Figure out the geospatial parameters from the STAC metadata (if possible): a coordinate reference system, resolution, and bounding box.\n",
    "> - Transfer the STAC metadata into xarray coordinates for easy indexing, filtering, and provenance of metadata.\n",
    "> - Efficiently generate a Dask graph for loading the data in parallel.\n",
    "> - Mediate between Dask’s parallelism and GDAL’s aversion to it, allowing for fast, multi-threaded reads when possible, and at least preventing segfaults when not.\n",
    "\n",
    "FYI: There's another project, `ods.stac` that does something similar. Check out _their_ [documentation](https://odc-stac.readthedocs.io/en/latest/).\n",
    "\n",
    "TBD which one wins :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "\n",
    "# bounds: (min_x, min_y, max_x, max_y)\n",
    "# https://linestrings.com/bbox/#-157,71.2,-156.5,71.35\n",
    "# epsg = 32604 -- native\n",
    "# epsg = 4326 wgs84\n",
    "# epsg = 3995\n",
    "# \n",
    "east, west, north, south = -156.7, -156.8, 71.3, 71.25\n",
    "stack = stackstac.stack(\n",
    "    item_collection[:10],\n",
    "    assets = ['nir'],\n",
    "    bounds_latlon = [west, south, east, north],\n",
    "    epsg = 4326,\n",
    "    #resolution = 0.001\n",
    ")\n",
    "stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.isel(time=slice(0, 6)).squeeze().plot.imshow(col=\"time\", col_wrap=3, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Forest Observatory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is an example of a _static_ STAC catalog. No API server here! Just a plain ol' JSON file in cloud storage, with links to other JSON files. We lose a lot of the rich interactivity we had with STAC APIs, but we can still manually navigate the catalog to learn about the items within it, and extract URLs to associated data assets.\n",
    "\n",
    "Open this in your web browser:\n",
    "https://storage.googleapis.com/cfo-public/catalog.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'https://storage.googleapis.com/cfo-public/catalog.json'\n",
    "catalog = Client.open(uri)\n",
    "catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = catalog.get_all_collections()\n",
    "for collection in collections:\n",
    "    print(f'[{collection.id}]: {collection.title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_collection = catalog.get_collection('wildfire').get_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_items = [item for item in wildfire_collection]\n",
    "wildfire_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(wildfire_items)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_assets = catalog \\\n",
    "    .get_collection('wildfire') \\\n",
    "    .get_item('California-Wildfire-BurnProbability-2020-Summer-00010m') \\\n",
    "    .assets\n",
    "wildfire_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_probability_asset = wildfire_assets['BurnProbability']\n",
    "burn_probability_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href = catalog \\\n",
    "    .get_collection('wildfire') \\\n",
    "    .get_item('California-Wildfire-BurnProbability-2020-Summer-00010m') \\\n",
    "    .assets['BurnProbability'] \\\n",
    "    .href\n",
    "href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(href, engine='rasterio', chunks={}).band_data\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
