{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, set your working directory to the course example folder\n",
    "import os\n",
    "os.chdir(os.path.expanduser('~/scalable-computing-examples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import gcsfs\n",
    "import fsspec\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Zarr dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a path to serve as the root of the Zarr storage hierarchy, and create a root-level group. Verify that something happened to create `data/example.zarr` on the local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = zarr.DirectoryStore('data/example.zarr')\n",
    "root = zarr.group(store=store, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add two Zarr groups called `temp` and `precip`. We haven't added any data yet! But what changes on the file system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.create_group('temp')\n",
    "root.create_group('precip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in the `temp` group, let's define a dataset called `t100`. We'll specify the overall shape of this array, the chunk sizes, the data type, and a fill value for missing data ... but no actual data yet! What does this create under `data/example.zarr` on the file system?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.temp.create_dataset('t100',\n",
    "                         shape=(10000, 10000),\n",
    "                         chunks=(1000, 1000),\n",
    "                         dtype='i4',\n",
    "                         fill_value=99,\n",
    "                         overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index on the first 5 rows and columns. Does it look like what you expect? Explain!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within our Python session, now let's create a 10,000 x 10,000 Zarr array of all 1's, specifying a 1K by 1K chunk size. To make it a little more interesting, let's replace the first row to the sequence 0...999. Note that this array only exists in memory for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precip = zarr.ones(shape=(10000, 10000),\n",
    "                   chunks=(1000, 1000),\n",
    "                   dtype='i4')\n",
    "precip[0, :] = np.arange(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index on the first 5 rows and columns. Does it look like what you expect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add this precip array to our file-based Zarr store, with the name `p100`. Then look again at the file system. What do you now see under the precip group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.precip['p100'] = precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go back to our t100 array, and assign 10 across the last\n",
    "# 3 row by 3 column subarray of the data\n",
    "\n",
    "# ... then index on the last 5 rows and columns. Does it looks like what you expect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what has changed under example.zarr on the file system? Does it make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, close the file store connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we can read our newly created Zarr store using the `zarr` library, and inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `zarr.open(<path>)` to read in your newly created Zarr store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try using the `tree()` method to visualize its structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the precip/p100 array look like what you created?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve CMIP6 data from a remote Zarr store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start out by reading a CSV file that catalogs all the available CMIP6 Zarr stores in this Google Cloud Storage account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row identifies a Zarr stores. How many are there in total?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the first few rows look like?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's use pandas to select CMIP zstore records corresponding to a simulation of the recent past (`historical`) from the ocean daily (`Oday`) table, focusing on the sea surface height (`tos`) variable. Weâ€™ll also only select results from the NOAA Geophysical Fluid Dynamics Laboratory (`NOAA-GFDL`) runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta = df.query(\"\"\"\n",
    "    activity_id=='CMIP' &\n",
    "    table_id == 'Oday' &\n",
    "    variable_id == 'tos' &\n",
    "    experiment_id == 'historical' &\n",
    "    institution_id == 'NOAA-GFDL'\n",
    "    \"\"\".replace('\\n', ''))\n",
    "df_ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above are sorted in version order, so we'll just take the final record, and retrieve the Zarr store path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zstore = df_ta.zstore.values[-1]\n",
    "print(f'zstore: {zstore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Zarr, we need to set up a MutableMapping interface to the storage system.\n",
    "\n",
    "We could use the gcsfs library for this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gcs = gcsfs.GCSFileSystem(token='anon')\n",
    "#mapper = gcs.get_mapper(zstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "But instead let's introduce `fsspec`, a useful library that abstracts over many kinds of local and remote connections. Here it detects that we're connecting to GCS, and internally uses the right implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = fsspec.get_mapper(zstore, token='anon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: To get a quick sense of what `fsspec` supports, run these two lines in a code cell:\n",
    "\n",
    "```python\n",
    "from fsspec.registry import known_implementations\n",
    "{k: v.get('class') for k, v in known_implementations.items()}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use xarray to reach into the Zarr store.\n",
    "\n",
    "Note that this will use Dask by default (if Dask is installed), automagically giving us a lazy, chunked representation of the data See [the docs](https://docs.xarray.dev/en/stable/user-guide/dask.html#reading-and-writing-data) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the ds dataset, and specifically the 'tos' data array\n",
    "# Notice the dimensionality and size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a tiny piece of the data, taking a lat slice of 71 to 73,\n",
    "# lon slice of 203 to 205, and time slice of 2010 to 2012\n",
    "\n",
    "\n",
    "# How big is this subset of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's create a pair of smaller summary datasets, first taking the mean for each day across our returned spatial grid cells, and then taking a 90-day rolling mean over the daily time series.\n",
    "\n",
    "Importantly, note that because we're working with Dask arrays, these are all lazy computations! We haven't loaded any data yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sst = tos_subset.mean(dim=('lat', 'lon'))\n",
    "rolling_90d_sst = daily_sst.rolling(time=90, center=True).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate a plot, which will force execution and therefore loading of actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sst.plot(label=\"daily\")\n",
    "rolling_90d_sst.plot(label=\"rolling annual mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exercise, you can try adding `.load()` at the end of the assignments above where we first calculated the daily mean and rolling mean, then try plotting again. Notice the speedup in plotting after we've pre-loaded the data in `daily_sst` and `rolling_90d_sst`. In this case, because those summary datasets are so small, this is safe and convenient, especially if we end up re-plotting many times to get the aesthetic details right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's try writing our small dataset out to a local Zarr store, just to see what it looks like on disk, then read it back in to verify everything is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our original subset out to a local Zarr store\n",
    "tos_subset.to_zarr('data/cmip_tos_subset.zarr', consolidated=True)\n",
    "\n",
    "# ... then open it again using xarray\n",
    "xr.open_dataset('data/cmip_tos_subset.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUR SST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do one more Zarr example, this time pulling SST data from an AWS S3 bucket. We'll use `fsspec` again. Note how similar this is to the code we used to connect to the CMIP6 data in GCS above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In case your don't have `s3fs` installed in your virtual environment,\n",
    "you can install it from within a Jupyter cell with the following command:\n",
    "```python\n",
    "!pip install s3fs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = 's3://mur-sst/zarr'\n",
    "\n",
    "mapper = fsspec.get_mapper(file_location, anon=True)\n",
    "ds_sst = xr.open_zarr(mapper, consolidated=True)\n",
    "\n",
    "# check out the size of this Zarr array!\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a 1-D time series of the sea_ice_fraction variable array,\n",
    "# extracting lat 73 and lon -157\n",
    "\n",
    "\n",
    "# How big is this subset of data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a quick time series plot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_ice_ts.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get a chunk of sea_ice_fraction for the year 2015,\n",
    "# slicing on lat 72.5 to 73, and lon -157.5 to -157\n",
    "\n",
    "# How big is this subset of data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our subset of data from 2015, calculate monthly mean sea ice fraction for all grid cells in this chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "monthly_mean_ice = sea_ice_chunk.groupby(\"time.month\").mean()\n",
    "monthly_mean_ice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's create a faceted plot visualizing the the ice area fraction by month across our little swath of spatial grid cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "fg = monthly_mean_ice.plot(\n",
    "    col=\"month\",\n",
    "    col_wrap=4,\n",
    "    cmap=mpl.cm.RdYlBu\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
